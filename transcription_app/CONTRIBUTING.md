# Voice to Text Project 
An audio transcription application. 

## ğŸ‘¨â€ğŸ’» Tech Stack

- **Python**
- **FastAPI**
- **Whisper AI**
- **OpenAI API (responses beta)**
- **pyannote-audio**
- **Jinja2 (HTML templating)**


## ğŸ“ Project Structure

```
transcription_app/
â”œâ”€â”€ output/                         
â”‚   â”œâ”€â”€ conversion_wav/             
â”‚   â”‚   â””â”€â”€ conversion.wav
â”‚   â”œâ”€â”€ diarization/                
â”‚   â”‚   â””â”€â”€ diarization_output.json
â”‚   â”œâ”€â”€ openai/                    
â”‚   â”‚   â””â”€â”€ summary.json
â”‚   â”œâ”€â”€ transcripts/                
â”‚   â”‚   â””â”€â”€ transcript.json
â”‚   â””â”€â”€ whisper/                    
â”‚       â””â”€â”€ whisper_transcript.json
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€filename.m4a                             
â”œâ”€â”€ app.py               
â”œâ”€â”€ diarization_service.py                
â”œâ”€â”€ requirements.txt               
â”œâ”€â”€ summary_agent.py               
â”œâ”€â”€ transcribe_audio.py           
â”œâ”€â”€ transcript_response.py                     
â”œâ”€â”€ CONTRIBUTING.md                      
â”œâ”€â”€ pyproject.toml 
```

### âš™ï¸ **Environment Setup**
Create a `.env` file in your project root with:

OPENAI_API_KEY=your-openai-key-here
SUMMARY_AGENT=you-agent-id
HUGGINGFACE_TOKEN=your-huggingface-key-here

### â–¶ï¸ **Running the App**

**Backend**
```bash
poetry run python app.py
```

---

## ğŸ“„ JSON Schema 

### Whisper Output
The Whisper response is structured like this:
```json
[
    {
        "start": "double",
        "end": "double",
        "text": "string",
        "speaker": "string"
    },
    {
        "start": "double",
        "end": "double",
        "text": "string",
        "speaker": "string"
    }
]
```

### Summery Output
The OpenAI response is structured like this:
```json
{
  "observations": "string",
  "key_points": {
    "account_status": "string",
    "customer_inquiry": "string",
    "account_issues": "string",
    "customer_service_response": "string",
    "outcome": "string"
  }
}
```

### Speaker Output
The pyannote-audio response is structured like this:
```json
[
    {
        "speaker": "string",
        "start": "double",
        "end": "double"
    },
    {
        "speaker": "string",
        "start": "double",
        "end": "double"
    },
    {
        "speaker": "string",
        "start": "double",
        "end": "double"
    },
    {
        "speaker": "string",
        "start": "double",
        "end": "double"
    },
    {
        "speaker": "string",
        "start": "double",
        "end": "double"
    }
]
```

 
### ğŸ“¤ **Example Output**
```json
{
  "observations": "The customer experienced a charge after cancellation...",
  "key_points": {
    "account_status": "The customer's account was suspended...",
    "customer_inquiry": "The customer inquired about billing discrepancies...",
    "account_issues": "The cancellation was not processed correctly...",
    "customer_service_response": "The agent acknowledged the error and escalated the case...",
    "outcome": "The customer was informed a follow-up would be provided."
  },
  "segments": [
    {
        "start": 0.0,
        "end": 7.92,
        "text": "Thank you for contacting Apex Services. This is Daniel in account support. How can I assist you today?",
        "speaker": "SPEAKER_00"
    },
    {
        "start": 7.92,
        "end": 14.8,
        "text": "Hi Daniel. I noticed that my account was suspended yesterday, but I also saw a charge of one hundred and forty-nine dollars for a service",
        "speaker": "SPEAKER_01"
    },
    {
        "start": 14.8,
        "end": 21.68,
        "text": "I thought I had canceled last month. Iâ€™m just a little confused about whatâ€™s going on.",
        "speaker": "SPEAKER_01"
    }
  ]
}
```


